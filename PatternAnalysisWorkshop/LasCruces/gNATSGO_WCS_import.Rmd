---
title: "gNATSGO -- Import via WCS for DSM comparisons"
author:
- D G Rossiter
- david.rossiter@wur.nl
date: "`r format(Sys.Date(), '%d-%B-%Y')`"
output:
  html_document:
    fig_align: center
    fig_height: 6
    fig_width: 6
    fig_caption: no
    number_section: yes
    theme: spacelab
    df_print: paged
    code_folding: show
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
params:
  lrc_long: -76
  lrc_lat: 42
  size: 1
  quantile.n: 2
  voi.n: 4
  depth.n: 1
  res: 250
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      purl=FALSE, 
                      fig.align = 'center')
knitr::opts_chunk$set(cache.extra = R.version.string, comment="")
```

# Introduction

[gNATSGO](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/survey/geo/?cid=nrcseprd1464625) "is a USDA-NRCS Soil & Plant Science Division (SPSD) composite database that provides complete coverage of the best available soils information for all areas of the United States and Island Territories. It was created by combining data from the Soil Survey Geographic Database (SSURGO), State Soil Geographic Database (STATSGO2), and Raster Soil Survey Databases (RSS) offsite link image into a single seamless ESRI file geodatabase."

It is thus the most authoritative digital product, representing many decades of field work and subsequent compilation.

Web Coverage Service (WCS) access is now provided by NRCS; we use that in this script.

This script creates a tile for a property and depth slice, over a Area of Interest delimited by geographic coordinates, in the WGS84 geographic coordinate reference system (EPSG:4326). 

This tile can then be compared with other DSM products. 

To use this script:


1. Adjust the [directory structure](#dirs) to your system

Steps 2--4 refer to the YAML headers of the R Markdown source document, or external calls with `knitr::render`. You can ask to be prompted for the parameters with the R command at the console:

```{r eval=FALSE}
rmarkdown::render("gNATSGO_WCS_import.Rmd", output_format = "html_document", 
                  params = "ask")
```

or you can specify them directly, e.g., 

```{r eval=FALSE}
rmarkdown::render("gNATSGO_WCS_import.Rmd", output_format = "html_document", 
                    params = list(lrc_long = -76, lrc_lat = 42, 
                                  size = 1, quantile.n = 2, voi.n = 3, res = 90))
```

See the respective sections of the code for the parameter definitions.

2. [Select a property and its value](#prop) (representative value, lower or upper estimated limits) and [select a depth slice](#depth), using the YAML header or by knitting with parameters.

3. [Select an Area of Interest](#aoi), typically a $1 \times 1^\circ$ tile, using the YAML header or by knitting with parameters.

4. [Select a grid resolution](#res), using the YAML header or by knitting with parameters.

4. Either compile to HTML or PDF ("knit") from the R Markdown toolbar, or "Run All" within R Markdown, or call `rmarkdown::render` from the R command line, as explained above.

5. The processed tile will be in the directory structure, in a [subdirectory named for the AOI](#save).

# Packages and Drivers

```{r pack}
library(sf)
library(terra)
library(aqp)
library(soilDB)
library(tidyverse)
library(rasterVis)
``` 


# Directories {#dirs}

One directory is used for the original files (map unit grids), and another for the attribute tiles. The latter will be used in the DSM comparison.

Set these to areas on your own system.

```{r}
base.dir.gnatsgo <- path.expand("~/ds_reference/Compare_DSM/gNATSGO/")
base.dir.gnatsgo.import <- path.expand("~/tmp/Compare_DSM/gNATSGO/")
```


# Parameters

Parameters for this run:

```{r}
print(paste("lrc_long:", params$lrc_long, "; lrc_lat:", 
            params$lrc_lat, "; size:", params$size))
print(paste("voi.n:", params$voi.n, "; quantile.n:", 
            params$quantile.n, "; depth.n:", params$depth.n))
```

## Property of interest and its value {#prop}

The following properties can be compared to SoilGrids250 and other DSM products.

Convert the "quantile" corresponding to 5%, 50%, 95%, mean in SoilGrids and POLARIS to:
`_l` (low), `_r` (representative value),  `_h` (high) and `_r` (again) as a suffix to the property name.
These are all estimates by expert opinion.


```{r voi.list}
# which property?
voi.list.sg <- c("clay", "silt", "sand", "phh2o", "cec", "soc", "bdod", "cfvo")
# which value? l, r, h, r
voi.val <- c("l", "r", "h", "r")[match(params$quantile.n, 
                                       c("1", "2", "3", "4"))] 
# which variable of interest?
voi.list.gnatsgo <- paste(c("claytotal", "silttotal", "sandtotal",
                            # note SOM not SOC
                            "ph1to1h2o", "cec7", "om", 
                            # which value? l, r, h, r
                            "dbthirdbar", "sieveno10"), 
                          voi.val, sep="_")
```

*Select a property* by its position in the list, and make a full name from it:

```{r voi}
(voi.name <- voi.list.gnatsgo[params$voi.n])
```


## Depth of interest {#depth}

Depth slices as specified by SoilGrids and gNATSGO.

```{r depth.list}
depth.list.sg <- c("0-5", "5-15", "15-30", "30-60", "60-100", "100-200")
depth.list.gnatsgo <- c("05", "515", "1530", "3060", "60100", "100200")
```

*Select a depth slice* by its position in the list, based on the YAML or run-time parameter, and make a full name from the property of interest and the selected depth slice:

```{r depth}
depth.gnatsgo <- depth.list.gnatsgo[params$depth.n]
(voi.depth.name <- paste0(voi.name, "_", depth.gnatsgo))  # , "cm"
```


## Area of Interest (AOI) {#aoi}

Specify the lower-right corner from the YAML or rendering parameters:

```{r lrc}
# lower-right corner
(tile.lrc <- c(params$lrc_long, params$lrc_lat))
```

Compute the upper-left corner:

```{r tile.1}
# Tile size, in integer degrees
size.long <- params$size; size.lat <- params$size
tile.ulc <- c(tile.lrc[1]-size.long, tile.lrc[2]+size.lat) # upper-left corner
m <- matrix(c(tile.ulc[1],tile.lrc[1],  #ulc
              tile.ulc[2], tile.lrc[2]  #lrc
              ),
            nrow=2)
bb.ll <- st_sfc(st_multipoint(m))
st_crs(bb.ll) <- 4326
print(bb.ll)
```

AOI in form needed for gNATSGO WCS import:

```{r wcs.aoi}
wcs.aoi <- list(
  aoi = c(tile.ulc[1],tile.lrc[2], tile.lrc[1], tile.ulc[2]),
  crs = '+init=EPSG:4326')
```

A prefix for directories, to keep AOI results separate.

```{r aoi.dir.prefix}
AOI.dir.prefix <- paste0("lat", tile.lrc[2], tile.ulc[2],
                         "_lon", tile.ulc[1], tile.lrc[1])
```

A directory to store the map unit tile and its linked database on import:

```{r save.tile}
(dest.dir.gnatsgo.import <-  paste0(base.dir.gnatsgo.import, 
                            AOI.dir.prefix))
if (!dir.exists(dest.dir.gnatsgo.import)) {
   dir.create(dest.dir.gnatsgo.import, recursive = TRUE)
}
```

A directory to save the processed tile:

```{r save.results}
base.dir.gnatsgo.import
(dest.dir <-  paste0(base.dir.gnatsgo, AOI.dir.prefix))
if (!dir.exists(dest.dir)) {
   dir.create(dest.dir, recursive = TRUE)
}
```

## Grid resolution  {#res}

```{r res}
(grid.res <- params$res)
```


# WCS access

The 30~m map unit raster takes about 16Mb per tile. The default EPSG code is 6350. This CRS is an Albers Equal Area with parameters suitable for the CONUS.

Do not repeat the WCS call if we already have the tile; if you want to make sure to have the most recent, delete any stored tile before calling.


```{r get.tile}
spc.name <- "mukey"
(spc.file <-  paste0(dest.dir.gnatsgo.import, "/", spc.name, "_", grid.res, ".tif"))
if (file.exists(spc.file)) {
  gn.m <- rast(spc.file)
} else {
  system.time(
    gn.m <- soilDB::mukey.wcs(db = 'gnatsgo', 
                                aoi = wcs.aoi, res = grid.res) # crs = "EPSG:6350"
  )
  names(gn.m) <- "mukey"
  class(gn.m)
#  gn.m <- terra::rast(gn.m)
  terra::writeRaster(gn.m, spc.file, overwrite = TRUE)  # extension  is .tif
}
st_crs(gn.m)$proj4string
st_bbox(gn.m)
```

```{r show.tile, fig.cap="Map units at 30m"}
rasterVis::levelplot(gn.m, att = 'ID', margin = FALSE, 
                     colorkey = FALSE, ask=FALSE)
```

The colours are from the map unit ID, they have no other meaning.

Map unit IDs:

```{r}
mu.list <- levels(gn.m)[[1]]
dim(mu.list)
head(mu.list)
```

There are `r dim(mu.list)[1]` unique map unit IDs in this window.
This is the basis of the RAT for eventual map reclassification; we will add the attribute values as a second field.

# Resample to WGS84 geographic coordinates

For comparison with other products, we want this in WGS84 geographic coordinates.

```{r to.wgs84}
gn.84 <- terra::project(gn.m, "epsg:4326", method = "near",
                              align = TRUE)
print(gn.84)
st_bbox(gn.84)
rasterVis::levelplot(gn.84, att = 'ID', margin = FALSE, 
                     colorkey = FALSE, ask=FALSE)
st_bbox(gn.84)
```

Note that the bounding box larger than the originally requested box, so that the original tile can be all represented in geographic coordinates.
So, crop to the original tile specification.

```{r mask.wgs84}
gn.84.crop <- crop(gn.84, bb.ll)
terra::plot(gn.84.crop, col=(sp::bpy.colors(50)))
```


# Attributes database

The Soil Data Access (SDA) web service has the information for each map unit. 
SDA from R is explained in [this tutorial](https://ncss-tech.github.io/AQP/soilDB/SDA-tutorial.html).

We have the map unit key, so get their information.

Query SDA by `mukey` for the map units in this tile.

This will bring down most of the interesting site / horizon level attributes from SSURGO/STATSGO, including the variable of interest.

Do not repeat the `fetchSDA` call if we already have the attributes for this tile; if you want to make sure to have the most recent, delete the stored `.rds` file before calling.

```{r}
spc.name <- "muinfo"
(spc.file <-  paste0(dest.dir.gnatsgo.import, "/", spc.name, "_", grid.res, ".rds"))
if (file.exists(spc.file)) {
  mu.info <- readRDS(spc.file)
} else {
  # Format vector of values into a string suitable for an SQL `IN` statement
  IS <- soilDB::format_SQL_in_statement(mu.list$ID)
  # query string -- all components
  ws <- sprintf("mukey IN %s", IS)
  system.time(
    mu.info <- suppressMessages(
      soilDB::fetchSDA(WHERE = ws, duplicates = TRUE, 
                       droplevels = TRUE, stringsAsFactors = FALSE,
                       childs = FALSE)
    )
  )
  saveRDS(mu.info, spc.file)
}
class(mu.info)
head(mu.info)
```


# Link to attribute of interest

Aggregate at component level for variable and depth interval of interest. For this we use the `aqp::slab()` function, "Aggregate soil properties along user-defined 'slabs', and optionally within groups".

Set up the depths and formula and then call the function:

```{r}
# the SoilGrids depths have the correct format
(slab.depths <- as.numeric(strsplit(depth.list.sg[params$depth.n],"-")[[1]]))
slab.fm <- formula(paste0("cokey ~ ", voi.name))
mu.attr <- aqp::slab(mu.info, slab.fm, 
            slab.structure = c(slab.depths[1], slab.depths[2]), 
            slab.fun = mean, na.rm = TRUE)
str(mu.attr)
warnings()[1]
```

This is a list of components, each with its attribute value for the depth slice.

For some tiles, some of the map units have incorrect horizonation.

Make an ID field for reshaping; this is the same for all components:

```{r}
mu.attr$variable.id <- sprintf("%s%s%s%s", 
                               mu.attr$variable, "_", 
                               mu.attr$top, 
                               mu.attr$bottom)
```

Long $\to$ wide format as a dataframe with two columns: the component key and the attribute value in the depth slice.

```{r}
mu.attr.w <- reshape2::dcast(mu.attr, cokey ~ variable.id, value.var = 'value')
str(mu.attr.w)
```

Get the components of each map unit from the site information, via `aqp::site`, and then add the map unit key and proportions to the data frame:

```{r}
mu.site <- aqp::site(mu.info)[, c('mukey', 'cokey', 'comppct_r')]
mu.site <- base::merge(mu.site, mu.attr.w, by = 'cokey', sort = FALSE)
```

So now we have the map unit, its components, their percentages of the map unit, and each component's attribute value averaged over the depth slice.

Split this into separate data frames for each map unit:

```{r split.mu.site}
mu.site.split <- base::split(mu.site, as.factor(mu.site$mukey), 
                             lex.order = TRUE)
```

Note that the list of data frames is in lexical order, i.e., the map unit code.

Look at the composition of the first map unit:

```{r show.first.mu.site}
(tmp <- mu.site.split[[1]])
sum(tmp$comppct_r)
```

This has `dim(tmp)[1]` components; their proportion adds to `round(sum(tmp$comppct_r),1`%, as we expect (or hope).

Now we have two ways to get properties from the map unit: weighted proportion or dominant component.

# Functions

## Weight the property value by the component proportions

Define a function to weight the property by the component proportions.

Arguments:

* `i`: map unit sequence in `mu.site.split` -- this will be called for all of them
* `var.name`: the name of variable to weighted
* `wt.name`: the name of the field containing the component proportions

Implicit argument (in scope):

* `mu.site.split`: a separate data frame for each site

```{r}
wt.mean.component <- function(i = 1, var.name, wt.name = 'comppct_r') {
  # make a local copy of this map unit's information
  mu.info.one <- mu.site.split[[i]]

  # get map unit ID, the list of component values and their weights
  mu.id <- as.character(mu.info.one[1, "mukey"])
  vals <- mu.info.one[,var.name]
  wts <- mu.info.one[,wt.name]

  # remove any list entries with NA in the values list or component proportions
  idx <- which(is.na(vals) | is.na(wts))
  if(length(idx) > 0) { mu.info.one <- mu.info.one[-idx, ] }

  # rebuild values and weights list w/o the components with missing values
  vals <- mu.info.one[,var.name]
  wts <- mu.info.one[,wt.name]

  # weighted mean -- note wts should sum to 100 but we don't assume that, because of possibl NA's
  mean.w <- sum(vals * wts) / sum(wts)
  
    # pack results into a one-line data frame
  result <- data.frame(
    mukey = mu.id,
    var = mean.w,
    stringsAsFactors = FALSE
  )
  # name  the variable field with the variable name.
  names(result)[2] <- var.name
  return(result)
}
```


# Reclassify raster map

Call the weight function for each map unit and add the result to the data frame of map unit IDs.
We have to match the map unit ID of the result with that of the map unit list in the RAT.

```{r build.weighted.result}
result.field <- "mean.val.aggr"
mu.list[ , result.field] <- as.numeric(NA)
for (i in 1:length(mu.site.split)) {
  mu.id <- as.character(mu.site.split[[i]][1, "mukey"])
  mean.wt <- wt.mean.component(i, voi.depth.name, "comppct_r")[, voi.depth.name]
  ix <- which(mu.list$ID == mu.id)
  mu.list[ix, result.field] <- mean.wt
}
mu.list$mukey <- as.numeric(mu.list$mukey)
mu.list <- mu.list[, 2:3]
head(mu.list)
```

This is now a `data.frame` that can be used as a  RAT (Raster Attribute Table).

Match each grid cell map unit ID with its value, using the RAT:

```{r deratify}
r.attr <- classify(gn.84.crop, mu.list)
summary(r.attr)
class(r.attr)
```

Rename the attribute:

```{r rename.attr}
names(r.attr)
names(r.attr) <- voi.name
names(r.attr)
```

Let's see how this looks:

```{r show.results.grid}
plot(r.attr)
rasterVis::levelplot(r.attr, layers = 1, margin = FALSE, colorkey = TRUE, ask=FALSE)
```

# Save tile {#save}

Save this map for further processing, e.g., comparing with SoilGrids250 or other DSM products.

Save the tile. Note that the file name includes the property name and depth slice. Specify the float-4 bit datatype and a GeoTIFF "world" file.  Each tile is about 14 Mb at 30~m resolution and 300 Kb at 250~m resolution.

```{r}
print(paste("file name:", 
            (fn <- paste0(dest.dir, "/", voi.depth.name , "_", grid.res, ".tif"))))
f <- terra::writeRaster(r.attr, filename=fn,
                        overwrite=TRUE, datatype="FLT4S",
                        gdal ="TFW=YES")
print(f)
```


